{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f636d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B value:  0.78\n"
     ]
    }
   ],
   "source": [
    "dimension = 512\n",
    "\n",
    "build_index_parameters = dict()\n",
    "distance_metric = 'l2'\n",
    "\n",
    "index_parameters = {'R': '64', 'L': '100', 'M': '16', 'B': '0.45'}\n",
    "\n",
    "B_value  = (0.25 + (250000*(4*int(index_parameters['R']) + 4*dimension)) / 2 ** 30)\n",
    "index_parameters['B'] = str(B_value)[:4]\n",
    "\n",
    "print(\"B value: \", index_parameters['B'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc0aa9",
   "metadata": {},
   "source": [
    "# download vector files from the h100-dell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71805d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "target_train_fvecs = '<target_location>:/local/eric/ft-vect-train/ft_size_' + str(dimension) + '/' + 'ft_' + str(dimension) + '.pack'\n",
    "target_validation_fvecs = '<target_location>:/local/eric/ft-vect-validation/ft_size_' + str(dimension) + '/' + 'ft_' + str(dimension) + '.pack'\n",
    "train_fvecs_name = 'ft_train_' + str(dimension) + '.pack'\n",
    "validation_fvecs_name = 'ft_validation_' + str(dimension) + '.pack'\n",
    "result = subprocess.run([\"rm\", \"-r\", \"data/tmp/\"], capture_output=True, text=True)\n",
    "result = subprocess.run([\"mkdir\", \"data/tmp/\"], capture_output=True, text=True)\n",
    "\n",
    "result = subprocess.run(['scp', target_train_fvecs, 'data/tmp/'+train_fvecs_name], capture_output=True, text=True)\n",
    "result = subprocess.run(['scp', target_validation_fvecs, 'data/tmp/'+validation_fvecs_name], capture_output=True, text=True)\n",
    "result = subprocess.run(['ls', 'data/tmp/'], capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: #pts = 1281167, # dims = 512\n",
      "# blks: 10\n",
      "Block #0 written\n",
      "Block #1 written\n",
      "Block #2 written\n",
      "Block #3 written\n",
      "Block #4 written\n",
      "Block #5 written\n",
      "Block #6 written\n",
      "Block #7 written\n",
      "Block #8 written\n",
      "Block #9 written\n",
      "\n",
      "Dataset: #pts = 50000, # dims = 512\n",
      "# blks: 1\n",
      "Block #0 written\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the fvecs to fbin\n",
    "target_index_fbin = \"ft_index_\" + str(dimension) + \".fbin\"\n",
    "target_query_fbins = \"ft_query_\" + str(dimension) + \".fbin\"\n",
    "result = subprocess.run([\"./apps/utils/fvecs_to_bin\", \"float\", \"data/tmp/\"+train_fvecs_name, \"data/tmp/\"+target_index_fbin], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "result = subprocess.run([\"./apps/utils/fvecs_to_bin\", \"float\", \"data/tmp/\"+validation_fvecs_name, \"data/tmp/\"+target_query_fbins], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "#result = subprocess.run(['rm', 'data/tmp/'+train_fvecs_name], capture_output=True, text=True)\n",
    "#result = subprocess.run(['rm', 'data/tmp/'+validation_fvecs_name], capture_output=True, text=True)\n",
    "\n",
    "# compute the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb4980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['./apps/utils/compute_groundtruth', '--data_type', 'float', '--dist_fn', 'ls', '--base_file', 'data/tmp/ft_index_512.fbin', '--query_file', 'data/tmp/ft_query_512.fbin', '--gt_file', 'data/tmp/ft_gt_512_gt1000', '--K', '10'], returncode=255, stdout='', stderr='Unsupported distance function. Use l2/mips/cosine.\\n')\n"
     ]
    }
   ],
   "source": [
    "# compute the ground truth\n",
    "gt_file_name = \"ft_gt_\" + str(dimension) + \"_gt1000\"\n",
    "result = subprocess.run([\"./apps/utils/compute_groundtruth\", \"--data_type\", \"float\", \"--dist_fn\", distance_metric, \"--base_file\", \"data/tmp/\"+target_index_fbin, \"--query_file\", \"data/tmp/\"+target_query_fbins, \"--gt_file\", \"data/tmp/\"+gt_file_name, \"--K\", \"10\"], capture_output=True, text=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a318250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data for cosine to temporary file, please ensure there is additional (n*d*4) bytes for storing normalized base vectors, apart from the interim indices created by DiskANN and the final index.\n",
      "Normalizing FLOAT vectors in file: data/tmp/ft_index_8.fbin\n",
      "Dataset: #pts = 1281167, # dims = 8\n",
      "# blks: 10\n",
      "Wrote normalized points to file: data/tmp/ft_graph_8_prepped_base.bin\n",
      "Time for preprocessing data for cosine: 0.038088 seconds\n",
      "Starting index build: R=64 L=100 Query RAM budget: 3.3286e+08 Indexing ram budget: 8 T: 12\n",
      "Compressing 8-dimensional data into 8 bytes per vector.\n",
      "Opened: data/tmp/ft_graph_8_prepped_base.bin, size: 40997352, cache_size: 40997352\n",
      "Training data with 256393 samples loaded.\n",
      "Processing chunk 0 with dimensions [0, 1)\n",
      "Processing chunk 1 with dimensions [1, 2)\n",
      "Processing chunk 2 with dimensions [2, 3)\n",
      "Processing chunk 3 with dimensions [3, 4)\n",
      "Processing chunk 4 with dimensions [4, 5)\n",
      "Processing chunk 5 with dimensions [5, 6)\n",
      "Processing chunk 6 with dimensions [6, 7)\n",
      "Processing chunk 7 with dimensions [7, 8)\n",
      "Writing bin: data/tmp/ft_graph_8_pq_pivots.bin\n",
      "bin: #pts = 256, #dims = 8, size = 8200B\n",
      "Finished writing bin.\n",
      "Writing bin: data/tmp/ft_graph_8_pq_pivots.bin\n",
      "bin: #pts = 8, #dims = 1, size = 40B\n",
      "Finished writing bin.\n",
      "Writing bin: data/tmp/ft_graph_8_pq_pivots.bin\n",
      "bin: #pts = 9, #dims = 1, size = 44B\n",
      "Finished writing bin.\n",
      "Writing bin: data/tmp/ft_graph_8_pq_pivots.bin\n",
      "bin: #pts = 4, #dims = 1, size = 40B\n",
      "Finished writing bin.\n",
      "Saved pq pivot data to data/tmp/ft_graph_8_pq_pivots.bin of size 12380B.\n",
      "Opened: data/tmp/ft_graph_8_prepped_base.bin, size: 40997352, cache_size: 40997352\n",
      "Reading bin file data/tmp/ft_graph_8_pq_pivots.bin ...\n",
      "Opening bin file data/tmp/ft_graph_8_pq_pivots.bin... \n",
      "Metadata: #pts = 4, #dims = 1...\n",
      "done.\n",
      "Reading bin file data/tmp/ft_graph_8_pq_pivots.bin ...\n",
      "Opening bin file data/tmp/ft_graph_8_pq_pivots.bin... \n",
      "Metadata: #pts = 256, #dims = 8...\n",
      "done.\n",
      "Reading bin file data/tmp/ft_graph_8_pq_pivots.bin ...\n",
      "Opening bin file data/tmp/ft_graph_8_pq_pivots.bin... \n",
      "Metadata: #pts = 8, #dims = 1...\n",
      "done.\n",
      "Reading bin file data/tmp/ft_graph_8_pq_pivots.bin ...\n",
      "Opening bin file data/tmp/ft_graph_8_pq_pivots.bin... \n",
      "Metadata: #pts = 9, #dims = 1...\n",
      "done.\n",
      "Loaded PQ pivot information\n",
      "Processing points  [0, 1281167)...done.\n",
      "Time for generating quantized data: 15.792277 seconds\n",
      "Full index fits in RAM budget, should consume at most 0.541799GiBs, so building in one shot\n",
      "L2: Using AVX2 distance computation DistanceL2Float\n",
      "Passed, empty search_params while creating index config\n",
      "Using only first 1281167 from file.. \n",
      "Starting index build with 1281167 points... \n",
      "\n",
      "0% of index build completed.\n",
      "7.80538% of index build completed.\n",
      "15.6108% of index build completed.\n",
      "23.4162% of index build completed.\n",
      "31.2215% of index build completed.\n",
      "39.0269% of index build completed.\n",
      "46.8323% of index build completed.\n",
      "54.6377% of index build completed.\n",
      "62.4431% of index build completed.\n",
      "70.2485% of index build completed.\n",
      "78.0538% of index build completed.\n",
      "85.8592% of index build completed.\n",
      "93.6646% of index build completed.Starting final cleanup..done. Link time: 20.1778s\n",
      "Index built with degree: max:64  avg:64  min:64  count(deg<2):0\n",
      "Not saving tags as they are not enabled.\n",
      "Time taken for save: 0.434813s.\n",
      "Time for building merged vamana index: 20.811815 seconds\n",
      "Opened: data/tmp/ft_graph_8_prepped_base.bin, size: 40997352, cache_size: 40997352\n",
      "Vamana index file size=333103444\n",
      "Opened: data/tmp/ft_graph_8_disk.index, cache_size: 67108864\n",
      "medoid: 936959B\n",
      "max_node_len: 292B\n",
      "nnodes_per_sector: 14B\n",
      "# sectors: 91512\n",
      "Sector #0written\n",
      "Finished writing 374837248B\n",
      "Writing bin: data/tmp/ft_graph_8_disk.index\n",
      "bin: #pts = 9, #dims = 1, size = 80B\n",
      "Finished writing bin.\n",
      "Output disk index file written to data/tmp/ft_graph_8_disk.index\n",
      "Finished writing 374837248B\n",
      "Time for generating disk layout: 0.362885 seconds\n",
      "Opened: data/tmp/ft_graph_8_prepped_base.bin, size: 40997352, cache_size: 40997352\n",
      "Loading base data/tmp/ft_graph_8_prepped_base.bin. #points: 1281167. #dim: 8.\n",
      "Wrote 99680 points to sample file: data/tmp/ft_graph_8_sample_data.bin\n",
      "Indexing time: 37.0423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_index = \"ft_graph_\" + str(dimension)\n",
    "result = subprocess.run(['./apps/build_disk_index', '--data_type', 'float', '--dist_fn', distance_metric, '--data_path', 'data/tmp/' + target_index_fbin, '--index_path_prefix', 'data/tmp/' + graph_index, '-R', index_parameters['R'], '-L'+index_parameters['L'], '-B' , index_parameters['B'], '-M', index_parameters['M']], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581f38e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search parameters: #threads: 12,  beamwidth: 2.\n",
      "Reading (with alignment) bin file data/tmp/ft_query_8.fbin ...[FUNC: void diskann::load_aligned_bin(const string&, T*&, size_t&, size_t&, size_t&) [with T = float; std::string = std::__cxx11::basic_string<char>; size_t = long unsigned int]][FILE: /home/xiangyu/working_dir/Utoronto/DiskANN/include/utils.h][LINE: 825]   While opening file 'data/tmp/ft_query_8.fbin', error code: 1  iostream error\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tmp/result.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#write stdout to file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/tmp/result.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(result\u001b[38;5;241m.\u001b[39mstdout)\n",
      "File \u001b[0;32m~/working_dir/Utoronto/DiskANN/build/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tmp/result.txt'"
     ]
    }
   ],
   "source": [
    "result_path = \"data/tmp/res\"\n",
    "result = subprocess.run(['./apps/search_disk_index', '--data_type', 'float', '--dist_fn', distance_metric, '--index_path_prefix', 'data/tmp/' + graph_index, '--query_file', 'data/tmp/' + target_query_fbins, '--gt_file', 'data/tmp/' + gt_file_name, '--result_path', result_path, '-K', '10', '-L', '10', '20', '30', '40', '50', '100', '--num_nodes_to_cache', '10000'], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "#write stdout to file\n",
    "with open('data/tmp/result.txt', 'w') as f:\n",
    "    f.write(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ae52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'data/tmp/'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['mv', 'data/tmp/', 'data/MRL_8_R64_L100_M8_B0.31_cosine'], returncode=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": No such file or directory\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(['mv', 'data/tmp/', 'data/MRL_' + str(dimension) + '_R' + index_parameters['R'] + '_L' + index_parameters['L'] + '_M' + index_parameters['M'] + '_B' + index_parameters['B'] + \"_\" + distance_metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
