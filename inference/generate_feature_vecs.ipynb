{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2c9acf-088e-4afd-8a4a-d702b49f1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../\") # adding root folder to the path\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import *\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MRL import *\n",
    "from imagenetv2_pytorch import ImageNetV2Dataset\n",
    "from argparse import ArgumentParser\n",
    "from utils import *\n",
    "\n",
    "# nesting list is by default from 8 to 2048 in powers of 2, can be modified from here.\n",
    "BATCH_SIZE = 1024\n",
    "IMG_SIZE = 256\n",
    "CENTER_CROP_SIZE = 224\n",
    "NESTING_LIST=[2**i for i in range(3, 12)]\n",
    "ROOT=\"/local/xiangyu/CSC2233/train/\" # path to validation datasets\n",
    "model_weight_path = \"/home/ericliu/csc2233/MRL/train/trainlogs/bfb14b69-f5c6-4754-958c-c7c522fe44be/final_weights.pt\"\n",
    "output_dir = \"/local/eric/ft-vect-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337d9948-7302-492a-b138-dd5959f35ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericliu/csc2233/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/ericliu/csc2233/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnet50(False, weights=None)\n",
    "model = load_from_old_ckpt(model, False, NESTING_LIST, extract_ft=True)\n",
    "apply_blurpool(model)\t\n",
    "model.load_state_dict(get_ckpt(model_weight_path)) # Since our models have a torch DDP wrapper, we modify keys to exclude first 7 chars. \n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "test_transform = transforms.Compose([\n",
    "\t\t\t\ttransforms.Resize(IMG_SIZE),\n",
    "\t\t\t\ttransforms.CenterCrop(CENTER_CROP_SIZE),\n",
    "\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t\tnormalize])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(ROOT+'val/', transform=test_transform)\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()} \n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd216913-2c38-401c-aae9-4152657c9e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:58<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "ft_to_vecs = {ft : [] for ft in NESTING_LIST}\n",
    "ft_to_label_to_vecs = {ft : {k : [] for k in dataset.class_to_idx} for ft in NESTING_LIST}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_inputs, labels in tqdm(dataloader):\n",
    "        logits = model(img_inputs.cuda())\n",
    "        label_names = [idx_to_class[label.item()] for label in labels]\n",
    "\n",
    "        for i, num_feat in enumerate(NESTING_LIST):\n",
    "            for ft_vec, label in zip(logits[i], label_names):\n",
    "                ft_vec = ft_vec.cpu()\n",
    "                ft_to_vecs[num_feat].append(ft_vec)\n",
    "                ft_to_label_to_vecs[num_feat][label].append(ft_vec)\n",
    "\n",
    "with open(f\"{output_dir}/ft_to_vecs.pkl\", \"wb\") as file:\n",
    "    pickle.dump(ft_to_vecs, file)\n",
    "\n",
    "with open(f\"{output_dir}/ft_to_label_to_vecs.pkl\", \"wb\") as file:\n",
    "    pickle.dump(ft_to_label_to_vecs, file)\n",
    "\n",
    "for num_feat, vecs in ft_to_vecs.items():\n",
    "    ft_dir = f\"{output_dir}/ft_size_{num_feat}\"\n",
    "    os.makedirs(ft_dir, exist_ok = True)\n",
    "    filepath = f\"{ft_dir}/ft_{num_feat}.pack\"\n",
    "    save_fvecs(filepath, vecs)\n",
    "\n",
    "for num_feat, label_to_vecs in ft_to_label_to_vecs.items():\n",
    "    ft_dir = f\"{output_dir}/ft_size_{num_feat}\"\n",
    "    os.makedirs(ft_dir, exist_ok = True)\n",
    "    for label, vecs in label_to_vecs.items():\n",
    "        out_dir = f\"{ft_dir}/{label}\"\n",
    "        os.makedirs(out_dir, exist_ok = True)\n",
    "        filepath = f\"{out_dir}/{label}.pack\"\n",
    "        save_fvecs(filepath, vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253a1bf-fdd8-4851-a834-e7152d17343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vecs = []\n",
    "all_labels = []\n",
    "for label, vecs in tqdm(ft_to_label_to_vecs[2048].items()):\n",
    "    all_vecs = all_vecs + vecs\n",
    "    all_labels = all_labels + [label] * len(vecs)\n",
    "all_vecs = torch.stack(all_vecs)\n",
    "all_vecs = all_vecs.numpy()\n",
    "\n",
    "with open(f\"{output_dir}/all_vecs.pkl\", \"wb\") as file:\n",
    "    pickle.dump(all_vecs, file)\n",
    "with open(f\"{output_dir}/all_labels.pkl\", \"wb\") as file:\n",
    "    pickle.dump(all_labels, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a249a06b-3884-48fb-8644-bf98b69597cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "with open(f\"{output_dir}/all_vecs.pkl\", \"rb\") as file:\n",
    "    all_vecs = pickle.load(file)\n",
    "with open(f\"{output_dir}/all_labels.pkl\", \"rb\") as file:\n",
    "    all_labels = pickle.load(file)\n",
    "\n",
    "vec_per_label = dict(Counter(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c214d7-8bf7-4736-9a80-c481ea0bd210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                   | 0/128117 [00:00<?, ?it/s]OpenBLAS warning: precompiled NUM_THREADS exceeded, adding auxiliary array for thread metadata.\n",
      "To avoid this warning, please rebuild your copy of OpenBLAS with a larger NUM_THREADS setting\n",
      "or set the environment variable OPENBLAS_NUM_THREADS to 64 or lower\n",
      "  0%|                                                                                       | 76/128117 [01:16<33:55:00,  1.05it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "x = np.array(all_vecs)\n",
    "k = vec_per_label[all_labels[0]]\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean').fit(x)\n",
    "\n",
    "for start in tqdm(range(0, all_vecs.shape[0], batch_size)):\n",
    "    end = min(start + batch_size, all_vecs.shape[0])\n",
    "    query_batch = all_vecs[start:end]\n",
    "    distances, indices = nn.kneighbors(all_vecs[start].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88743bf8-52b4-46a4-93bd-8d97f97ec054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4656.64it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vecs = []\n",
    "all_labels = []\n",
    "\n",
    "with open(\"/local/eric/ft-vect-validation/ft_to_label_to_vecs.pkl\", \"rb\") as file:\n",
    "    ft_to_label_to_vecs = pickle.load(file)\n",
    "\n",
    "for label, vecs in tqdm(ft_to_label_to_vecs[2048].items()):\n",
    "    all_vecs = all_vecs + vecs\n",
    "    all_labels = all_labels + [label] * len(vecs)\n",
    "all_vecs = torch.stack(all_vecs)\n",
    "all_vecs = all_vecs.numpy()\n",
    "\n",
    "with open(f\"{output_dir}/all_vecs.pkl\", \"wb\") as file:\n",
    "    pickle.dump(all_vecs, file)\n",
    "with open(f\"{output_dir}/all_labels.pkl\", \"wb\") as file:\n",
    "    pickle.dump(all_labels, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
